# Story 1.2: Development Environment Setup

**Status:** Draft

## Non-Technical Explanation

Think of this story as preparing a workshop where all our builders will create the application packaging system. We need to make sure everyone has the exact same tools (software), workbench setup (configuration), and test materials (sample data) to work with. It's like creating a "kit" that any team member can use to instantly set up their workspace with everything needed to start building the system.

Just as a chef ensures all kitchen staff have the right knives, ingredients, and recipes before service begins, we're making sure all developers have the right software versions, dependencies, and configuration before development begins.

## Why This Matters

Without a consistent development environment, team members might use different versions of tools or configurations, leading to the frustrating "but it works on my machine" problem. This could cause delays, bugs that only appear for some developers, and wasted time troubleshooting environment issues. By creating a reproducible environment with automated setup scripts, we ensure everyone can work efficiently with the same tools and settings.

## Goal & Context

**User Story:** As a developer, I need a consistent and fully-configured development environment to efficiently build the APAS multi-agent system.

**Context:** This story builds upon the architectural design established in Story 1.1 by creating a reproducible development environment where developers can build and test the system. A properly configured environment ensures consistent development across the team and prevents "works on my machine" issues.

## Detailed Requirements

- Create a reproducible development environment specification
- Include all necessary dependencies for AI/ML components for all agents
- Configure appropriate Python/Node.js versions and packages
- Set up inter-agent communication testing framework
- Set up local database for development
- Include test data samples for application installers
- Create environment validation tests
- Document environment setup process

## Acceptance Criteria (ACs)

- AC1: Development environment can be set up from documentation in less than 2 hours
- AC2: Environment includes all necessary dependencies for all agent types
- AC3: Sample test data is available for local testing
- AC4: Environment validation tests pass successfully
- AC5: Inter-agent communication can be tested locally
- AC6: Documentation clearly explains setup process and troubleshooting

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Refer to the linked `docs/` files for broader context if needed.

- **Relevant Files:**

  - Files to Create: 
    - `scripts/setup_dev.ps1` - PowerShell script for environment setup
    - `scripts/setup_supabase.ps1` - Script for local Supabase instance setup
    - `backend/pyproject.toml` - Python dependency specifications
    - `backend/poetry.lock` - Locked Python dependencies
    - `frontend/package.json` - Node.js dependency specifications
    - `backend/.env.example` - Example environment variables
    - `frontend/.env.example` - Example frontend environment variables
    - `data/test_installers/` - Directory for test installer files
    - `docs/development-environment.md` - Development environment documentation
  - Files to Modify:
    - `.gitignore` - Add environment-specific entries
    - `README.md` - Add development setup instructions
  - _(Hint: See `docs/architecture/project-structure.md` for overall layout)_

- **Key Technologies:**

  - Python 3.11+ with Poetry for dependency management
  - Node.js 20.x LTS with npm/yarn
  - Git for version control
  - Docker for local Supabase instance
  - PowerShell 7.x for setup scripts
  - Visual Studio Code (recommended IDE)
  - Local Supabase instance for database, storage, and auth
  - _(Hint: See `docs/architecture/tech-stack.md` for full list)_

- **API Interactions / SDK Usage:**

  - Supabase SDK for database interactions
  - LangChain for AI agent framework
  - HuggingFace Transformers for ML models
  - None of these need to be fully implemented yet, just installed for development
  - _(Hint: See `docs/architecture/api-reference.md` for details)_

- **Data Structures:**

  - Sample installer files need to be provided in standard formats (MSI, EXE, MSIX)
  - Example application metadata in JSON format for testing
  - _(Hint: See `docs/architecture/data-models.md` for data structure details)_

- **Environment Variables:**

  - `SUPABASE_URL` - Local Supabase URL
  - `SUPABASE_KEY` - Local Supabase anonymous key
  - `PYTHONPATH` - Set to include project root
  - Development-specific variables detailed in .env.example files
  - _(Hint: See `docs/architecture/environment-vars.md` for details)_

- **Coding Standards Notes:**
  - Follow Python PEP 8 style guide
  - Use ESLint and Prettier for JavaScript/TypeScript
  - Document setup script with comments explaining each step
  - Use consistent formatting in configuration files
  - _(Hint: See `docs/architecture/coding-standards.md` for full standards)_

## Visual Design Reference

The development environment setup should result in a file structure that looks like:

```
apas/
├── backend/
│   ├── pyproject.toml         # Contains Python dependencies
│   ├── poetry.lock            # Locked dependencies for consistency
│   ├── .env                   # Environment variables (git-ignored)
│   └── apas/                  # Actual Python package
├── frontend/
│   ├── package.json           # Contains Node.js dependencies
│   ├── tsconfig.json          # TypeScript configuration
│   ├── .env                   # Frontend environment variables (git-ignored)
│   └── src/                   # Frontend source code
├── scripts/
│   ├── setup_dev.ps1          # Main setup script
│   └── setup_supabase.ps1     # Supabase setup script
├── supabase/
│   ├── docker-compose.yml     # Docker configuration for local Supabase
│   └── migrations/            # Database migrations
├── data/
│   └── test_installers/       # Sample installer files for testing
├── .vscode/
│   └── settings.json          # VS Code settings for consistency
└── docs/
    └── development-environment.md  # Setup documentation
```

The setup process should be executable with a single command that installs all dependencies, configures the local environment, and validates the setup.

## Tasks / Subtasks

- [ ] Create Python environment setup
  - [ ] Set up Poetry for Python dependency management
  - [ ] Define required Python packages in pyproject.toml
  - [ ] Configure Python version requirements
  - [ ] Create virtual environment setup instructions
- [ ] Create Node.js environment setup
  - [ ] Define npm/yarn configuration
  - [ ] Specify required Node.js packages in package.json
  - [ ] Set up TypeScript configuration
- [ ] Set up local Supabase instance
  - [ ] Create Docker configuration for Supabase
  - [ ] Set up initialization scripts for database schema
  - [ ] Configure local storage buckets
  - [ ] Document local Supabase access
- [ ] Create setup automation scripts
  - [ ] Develop PowerShell script for environment setup
  - [ ] Include validation checks in scripts
  - [ ] Add troubleshooting guidance in scripts
- [ ] Gather sample test data
  - [ ] Collect sample installer files (MSI, EXE, MSIX)
  - [ ] Create sample application metadata files
  - [ ] Document test data contents and usage
- [ ] Create environment validation tests
  - [ ] Implement dependency version checks
  - [ ] Create database connectivity tests
  - [ ] Develop inter-agent communication tests
- [ ] Document development environment
  - [ ] Create comprehensive setup guide
  - [ ] Include troubleshooting section
  - [ ] Document environment validation process
  - [ ] Add sections for different operating systems if needed

## Manual Testing Guide (For Non-Technical Users)

While this story is primarily technical, there are aspects you can verify to ensure the development environment is properly set up:

1. **Setup Documentation Review**:
   - Check that the development environment documentation exists
   - Verify that the documentation is clear and comprehensive
   - Confirm that the setup process is well-documented with step-by-step instructions
   - Check that there is a troubleshooting section that addresses common issues

2. **Setup Demonstration**:
   - Ask a developer to demonstrate the setup process on a clean machine
   - Verify that the setup completes successfully within the 2-hour timeframe
   - Confirm that the validation tests run automatically at the end of setup

3. **Sample Data Verification**:
   - Check that the `data/test_installers/` directory exists and contains sample files
   - Verify that there is documentation explaining what each sample file is for
   - Confirm that the sample data is appropriate for testing the system

4. **Expected Results**:
   - The setup process should be automated with minimal manual intervention
   - The environment should include all necessary tools and dependencies
   - The validation tests should pass successfully
   - The documentation should be clear enough for a new developer to follow

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests.

- **Unit Tests:** 
  - Create a simple test script that verifies all dependencies are correctly installed
  - Test database connection to local Supabase instance
  - Verify Python environment is properly configured

- **Integration Tests:** 
  - Test basic inter-agent communication in the local environment
  - Verify Supabase API functionality with simple CRUD operations

- **Manual Verification:** 
  - Follow the setup documentation on a clean machine to verify it works as expected
  - Verify all setup scripts run without errors
  - Confirm environment can be set up within the 2-hour timeframe
  - Check that all sample data is accessible and in the correct format
  - Verify that a new developer can understand and execute the setup process

## AI Dev Agent Implementation Notes

- The setup script should be robust, with proper error handling and clear error messages
- The script should check for prerequisites and provide helpful guidance if any are missing
- Use checkpoints in the setup process to allow for resuming if something fails
- Focus on making the environment as reproducible as possible across different machines
- Include verification steps after each major component is set up
- Consider creating a cleanup/uninstall script as well to help with troubleshooting
- For sample test data, include a variety of installer types to cover different scenarios
- Documentation should include screenshots or diagrams where appropriate

## Implementation Example

Here's an example of how the validation test script might be implemented:

```python
# validate_environment.py

import importlib
import sys
import os
import subprocess
from pathlib import Path

def check_python_version():
    """Verify Python version meets requirements."""
    required_version = (3, 11)
    current_version = sys.version_info
    
    if current_version < required_version:
        print(f"❌ Python version {current_version.major}.{current_version.minor} detected.")
        print(f"   Required version is {required_version[0]}.{required_version[1]}+")
        return False
    
    print(f"✅ Python version {current_version.major}.{current_version.minor} meets requirements.")
    return True

def check_dependencies():
    """Verify required Python packages are installed."""
    required_packages = [
        "fastapi", "sqlalchemy", "pydantic", "langchain", 
        "transformers", "supabase", "pytest", "structlog"
    ]
    
    all_installed = True
    for package in required_packages:
        try:
            importlib.import_module(package)
            print(f"✅ Package {package} is installed.")
        except ImportError:
            print(f"❌ Package {package} is not installed.")
            all_installed = False
    
    return all_installed

def check_supabase():
    """Verify Supabase is running and accessible."""
    try:
        from supabase import create_client
        
        url = os.environ.get("SUPABASE_URL")
        key = os.environ.get("SUPABASE_KEY")
        
        if not url or not key:
            print("❌ SUPABASE_URL or SUPABASE_KEY environment variables not set.")
            return False
        
        client = create_client(url, key)
        # Simple test query
        response = client.table("test").select("*").limit(1).execute()
        
        print("✅ Successfully connected to Supabase.")
        return True
    except Exception as e:
        print(f"❌ Failed to connect to Supabase: {str(e)}")
        return False

def main():
    """Run all validation checks."""
    print("=== APAS Development Environment Validation ===\n")
    
    # Run checks
    python_ok = check_python_version()
    deps_ok = check_dependencies()
    supabase_ok = check_supabase()
    
    # Summary
    print("\n=== Validation Summary ===")
    if python_ok and deps_ok and supabase_ok:
        print("✅ All validation checks passed! Environment is correctly set up.")
        return 0
    else:
        print("❌ Some validation checks failed. Please review the issues above.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
```

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** 
- **Completion Notes:** 
- **Change Log:** 
  - Initial Draft
  - Updated with non-technical explanation, visual references, and manual testing guide
