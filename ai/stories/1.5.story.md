# Story 1.5: Logging and Telemetry System

**Status:** Draft

## Non-Technical Explanation

Think of this story as installing cameras, sensors, and monitoring tools throughout our AI system. Just like a factory might have cameras to watch production, gauges to measure performance, and alarms to signal problems, our system needs similar tools to monitor what's happening and quickly identify issues.

We're building three key monitoring systems:
1. A **logging system** that records all important events and actions (like a security camera system)
2. A **telemetry system** that measures performance and resource usage (like gauges and meters)
3. A **tracing system** that follows requests as they move through different AI agents (like tracking a package through a delivery system)

These tools give us visibility into what's happening inside the system, help us troubleshoot problems, and allow us to monitor performance and health over time.

## Why This Matters

Without proper logging and monitoring, we would be flying blind. If something goes wrong, we wouldn't know where the problem occurred or why. Performance issues would be difficult to identify, and troubleshooting would be like finding a needle in a haystack.

This story ensures that:
1. We can see what each AI agent is doing and why
2. We can track how requests flow between agents
3. We can measure performance and identify bottlenecks
4. We can troubleshoot issues quickly and effectively
5. We have historical data for analyzing patterns and trends

Just as a doctor needs diagnostic tools to understand what's happening inside a patient's body, we need these monitoring tools to understand what's happening inside our AI system.

## Goal & Context

**User Story:** As a developer and operations team, we need comprehensive logging and telemetry to monitor system performance, agent activities, and troubleshoot issues.

**Context:** This story builds upon the multi-agent framework (Story 1.4) by implementing a comprehensive logging and telemetry system that provides visibility into the operation of the APAS system. This system will enable developers to monitor agent activities, track performance metrics, and troubleshoot issues effectively.

## Detailed Requirements

- Implement structured logging throughout the system
- Create specialized logging for agent activities and communications
- Develop telemetry for system and individual agent performance metrics
- Implement tracing for request flows across multiple agents
- Create log aggregation and search capabilities
- Design rotation and archiving for log files
- Document logging standards and practices

## Acceptance Criteria (ACs)

- AC1: System generates structured logs at appropriate levels for all components and agents
- AC2: Performance metrics are captured accurately for the system and individual agents
- AC3: Request flows can be traced across multiple agents
- AC4: Logs are properly rotated and archived
- AC5: Log search provides efficient access to relevant information
- AC6: Agent interactions are properly logged for debugging and analysis

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Refer to the linked `docs/` files for broader context if needed.

- **Relevant Files:**

  - Files to Create: 
    - `backend/apas/utils/logging.py` - Logging utilities and configuration
    - `backend/apas/utils/telemetry.py` - Telemetry collection utilities
    - `backend/apas/utils/tracing.py` - Request tracing utilities
    - `backend/apas/core/observability/` - Observability framework
    - `docs/developer-guide/logging.md` - Logging documentation
    - `docs/developer-guide/telemetry.md` - Telemetry documentation
  - Files to Modify:
    - `backend/apas/core/orchestration/orchestrator.py` - Add logging
    - `backend/apas/core/event_bus/event_bus.py` - Add logging and tracing
    - `backend/apas/agents/base.py` - Add logging and telemetry
    - `backend/apas/config.py` - Add logging configuration
  - _(Hint: See `docs/architecture/project-structure.md` for overall layout)_

- **Key Technologies:**

  - Python logging module for basic logging
  - Structlog for structured logging
  - OpenTelemetry for tracing and metrics
  - Prometheus client for metrics collection (optional)
  - ELK stack or similar for log aggregation (optional for local dev)
  - _(Hint: See `docs/architecture/tech-stack.md` for details)_

- **API Interactions / SDK Usage:**

  - OpenTelemetry API for distributed tracing
  - Prometheus client for metrics exposition
  - Structlog for context-aware logging
  - _(Hint: See `docs/architecture/api-reference.md` for API patterns)_

- **Data Structures:**

  - LogRecord structure with consistent fields
  - Span and Trace structures for request tracing
  - Metric structures for performance monitoring
  - _(Hint: See `docs/architecture/data-models.md` for structure details)_

- **Environment Variables:**

  - `LOG_LEVEL` - Logging level (DEBUG, INFO, WARNING, ERROR)
  - `LOG_FORMAT` - Log format (JSON, text)
  - `LOG_FILE` - Log file location or 'stdout'
  - `TELEMETRY_ENABLED` - Enable/disable telemetry collection
  - `TRACING_ENABLED` - Enable/disable distributed tracing
  - _(Hint: See `docs/architecture/environment-vars.md` for details)_

- **Coding Standards Notes:**
  - Use structured logging throughout the codebase
  - Include correlation IDs in all logs for request tracing
  - Log at appropriate levels (DEBUG, INFO, WARNING, ERROR)
  - Include context in log messages
  - Use metrics for performance-sensitive operations
  - Implement trace context propagation across component boundaries
  - _(Hint: See `docs/architecture/coding-standards.md` for full standards)_

## Visual Design Reference

The logging and telemetry system architecture will have components that work together like this:

```
Application Components
┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐
│ Agent 1 │  │ Agent 2 │  │ Event  │  │Orches- │
│        │  │        │  │ Bus    │  │trator  │
└────┬───┘  └────┬───┘  └────┬───┘  └────┬───┘
     │           │           │           │
     ▼           ▼           ▼           ▼
┌─────────────────────────────────────────────┐
│            Logging Framework                 │
│  ┌─────────┐ ┌─────────┐ ┌─────────────┐    │
│  │Structured│ │Context  │ │Correlation  │    │
│  │Logging   │ │Processor│ │ID Tracker   │    │
│  └─────────┘ └─────────┘ └─────────────┘    │
└───────────────────────┬─────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────┐
│           Output Routing                     │
│  ┌─────────┐ ┌─────────┐ ┌─────────────┐    │
│  │Console  │ │File     │ │Log          │    │
│  │Output   │ │Output   │ │Aggregation  │    │
│  └─────────┘ └─────────┘ └─────────────┘    │
└─────────────────────────────────────────────┘

┌─────────────────────────────────────────────┐
│            Telemetry System                  │
│  ┌─────────┐ ┌─────────┐ ┌─────────────┐    │
│  │Metrics  │ │Counters │ │Gauges &     │    │
│  │Collector│ │        │ │Histograms    │    │
│  └─────────┘ └─────────┘ └─────────────┘    │
└───────────────────────┬─────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────┐
│            Tracing System                    │
│  ┌─────────┐ ┌─────────┐ ┌─────────────┐    │
│  │Trace    │ │Span     │ │Context      │    │
│  │Context  │ │Manager  │ │Propagation  │    │
│  └─────────┘ └─────────┘ └─────────────┘    │
└─────────────────────────────────────────────┘
```

The system will use structured logging to ensure consistent log formats, correlation IDs to track related events, and context processors to add relevant information. The telemetry system will collect performance metrics, while the tracing system will track request flows across multiple agents.

## Tasks / Subtasks

- [ ] Design logging architecture
  - [ ] Define log levels and their usage
  - [ ] Create structured log format
  - [ ] Design log configuration system
  - [ ] Create logging utilities
- [ ] Implement core logging
  - [ ] Set up structlog integration
  - [ ] Create log formatters
  - [ ] Implement log router for different outputs
  - [ ] Add context processors for additional information
- [ ] Develop telemetry system
  - [ ] Design metric collection framework
  - [ ] Implement counters, gauges, and histograms
  - [ ] Create telemetry reporting endpoints
  - [ ] Set up performance metric collection
- [ ] Implement distributed tracing
  - [ ] Create trace context propagation
  - [ ] Implement span creation and management
  - [ ] Set up trace correlation with logs
  - [ ] Create trace visualization utilities
- [ ] Set up log management
  - [ ] Implement log rotation
  - [ ] Create log archiving mechanism
  - [ ] Set up log searching functionality
  - [ ] Develop log analysis utilities
- [ ] Integrate logging into core components
  - [ ] Add logging to orchestration layer
  - [ ] Implement logging in event bus
  - [ ] Add telemetry to agent base class
  - [ ] Set up tracing for cross-agent workflows
- [ ] Document logging system
  - [ ] Create logging standards documentation
  - [ ] Document telemetry system and metrics
  - [ ] Create tracing documentation
  - [ ] Document log analysis approaches

## Manual Testing Guide (For Non-Technical Users)

While logging and telemetry are technical topics, there are aspects you can verify to ensure the system is working properly:

1. **Log Visibility Check**:
   - Ask for a demonstration of the system performing a simple task
   - Check that logs are being generated and display clear, readable information
   - Verify that important events are being recorded
   - Confirm that log messages include relevant context

2. **Tracing Demonstration**:
   - Ask to see a trace of a request flowing through multiple agents
   - Verify that you can follow the request from start to finish
   - Check that the trace shows the timing of each step
   - Confirm that related logs are linked to the trace

3. **Performance Metrics Review**:
   - Ask to see the telemetry dashboard or reports
   - Check that key metrics like response time and throughput are being tracked
   - Verify that metrics are reported for both the system as a whole and individual agents
   - Confirm that historical metrics are available for trend analysis

4. **Expected Results**:
   - Logs should be clear, consistent, and provide useful information
   - Traces should show the complete flow of requests through the system
   - Performance metrics should accurately reflect system behavior
   - The system should enable quick troubleshooting of issues

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests.

- **Unit Tests:** 
  - Test logging configuration and levels
  - Verify log formatting and structure
  - Test metric collection accuracy
  - Validate trace context propagation
  - Test log rotation functionality

- **Integration Tests:** 
  - Verify logging across component boundaries
  - Test tracing for end-to-end requests
  - Validate metric aggregation
  - Test log search functionality
  - Verify context propagation in distributed operations

- **Manual Verification:** 
  - Review log output for readability and completeness
  - Verify that logs contain necessary context for debugging
  - Check that performance metrics accurately reflect system behavior
  - Confirm that traces properly connect related operations
  - Validate that logs are properly rotated and archived
  - Test log search functionality with realistic queries

## AI Dev Agent Implementation Notes

- Focus on creating a consistent, structured logging approach throughout the system
- Ensure correlation IDs are propagated across all agent boundaries
- Use appropriate log levels to avoid overwhelming logs with unnecessary information
- Consider performance impact of logging, especially in high-volume operations
- Implement log sampling for high-volume events to reduce storage requirements
- Make sure trace context propagation works correctly across asynchronous boundaries
- Provide useful helper functions to make logging consistent across the codebase
- Consider security implications of logging sensitive information
- Include system health metrics in the telemetry system
- Use meaningful metric names and labels for easy interpretation

## Implementation Example

Here's an example of how the structured logging setup might be implemented:

```python
import logging
import structlog
import time
from typing import Dict, Any, Optional
import uuid
import sys

def setup_logging(
    log_level: str = "INFO",
    log_format: str = "json",
    log_file: Optional[str] = None,
    service_name: str = "apas"
) -> None:
    """
    Configure structured logging for the application.
    
    Args:
        log_level: Logging level (DEBUG, INFO, WARNING, ERROR)
        log_format: Output format (json, console)
        log_file: Log file path or None for stdout
        service_name: Name of the service for identification
    """
    # Convert string log level to logging constant
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)
    
    # Common processors for all outputs
    processors = [
        # Add timestamp to the log record
        structlog.processors.TimeStamper(fmt="iso"),
        # Add contextual information
        structlog.contextvars.merge_contextvars,
        # Add caller information
        structlog.processors.add_log_level,
        structlog.processors.StackInfoRenderer(),
        # Add correlation ID if not present
        add_correlation_id,
        # Add service name
        structlog.processors.add_log_level_number,
        lambda _, __, event_dict: {"service": service_name, **event_dict},
    ]
    
    # Format-specific processors
    if log_format.lower() == "json":
        processors.append(structlog.processors.format_exc_info)
        processors.append(structlog.processors.JSONRenderer())
    else:
        processors.append(structlog.dev.ConsoleRenderer())
    
    # Configure structlog
    structlog.configure(
        processors=processors,
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    
    # Configure standard logging
    handlers = []
    if log_file:
        handlers.append(logging.FileHandler(log_file))
    else:
        handlers.append(logging.StreamHandler(sys.stdout))
    
    logging.basicConfig(
        format="%(message)s",
        level=numeric_level,
        handlers=handlers,
    )

def add_correlation_id(_, __, event_dict: Dict[str, Any]) -> Dict[str, Any]:
    """
    Add correlation ID to the log record if not present.
    """
    if "correlation_id" not in event_dict:
        event_dict["correlation_id"] = str(uuid.uuid4())
    return event_dict

def get_logger(name: str) -> structlog.stdlib.BoundLogger:
    """
    Get a structured logger with the given name.
    """
    return structlog.get_logger(name)
```

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** 
- **Completion Notes:** 
- **Change Log:** 
  - Initial Draft
  - Updated with non-technical explanation, visual references, and manual testing guide
